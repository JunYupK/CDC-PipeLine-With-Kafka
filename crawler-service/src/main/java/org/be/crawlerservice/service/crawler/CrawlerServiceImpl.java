package org.be.crawlerservice.service.crawler;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import jakarta.persistence.EntityManager;
import jakarta.transaction.Transactional;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.be.crawlerservice.client.Crawl4AIClient;
import org.be.crawlerservice.client.schema.NaverNewsSchemas;
import org.be.crawlerservice.dto.crawl4ai.Crawl4AIRequest;
import org.be.crawlerservice.dto.crawl4ai.Crawl4AIResult;
import org.be.crawlerservice.dto.crawl4ai.StreamingCrawlResult;
import org.be.crawlerservice.dto.request.CrawlRequestDto;
import org.be.crawlerservice.dto.response.CrawlStatusDto;
import org.be.crawlerservice.dto.response.StatsResponseDto;
import org.be.crawlerservice.entity.Article;
import org.be.crawlerservice.entity.Media;
import org.be.crawlerservice.enums.CrawlerStatus;
import org.be.crawlerservice.metrics.CrawlerMetrics;
import org.be.crawlerservice.repository.ArticleRepository;
import org.be.crawlerservice.repository.MediaRepository;
import org.be.crawlerservice.service.article.ArticleService;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import org.springframework.util.StringUtils;

import java.net.MalformedURLException;
import java.net.URL;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.concurrent.atomic.AtomicReference;
import java.util.stream.Stream;

@Slf4j
@Service
@RequiredArgsConstructor
public class CrawlerServiceImpl implements CrawlerService {

    private final ArticleService articleService;
    private final CrawlerMetrics crawlerMetrics;
    private final Crawl4AIClient crawl4AIClient;
    private final ObjectMapper objectMapper;
    private final ArticleRepository articleRepository;
    private final MediaRepository mediaRepository;

    // í¬ë¡¤ë§ ìƒíƒœ ê´€ë¦¬
    private final AtomicBoolean isCrawling = new AtomicBoolean(false);
    private final AtomicBoolean isDeepCrawling = new AtomicBoolean(false);
    private final AtomicReference<String> currentCategory = new AtomicReference<>();
    private final AtomicReference<LocalDateTime> crawlStartTime = new AtomicReference<>();
    private final Map<String, Integer> errorCounts = new ConcurrentHashMap<>();
    private final Map<String, LocalDateTime> lastExecutionTimes = new ConcurrentHashMap<>();
    private CompletableFuture<Void> currentCrawlTask;
    private final AtomicInteger processedCount = new AtomicInteger(0);
    private final AtomicInteger totalCount = new AtomicInteger(0);

    // Deep Crawling ì „ìš© ìƒíƒœ ê´€ë¦¬
    private final AtomicInteger deepCrawlProcessedCount = new AtomicInteger(0);
    private final AtomicInteger deepCrawlSavedCount = new AtomicInteger(0);

    // í•˜ì´ë¸Œë¦¬ë“œ í¬ë¡¤ë§ì„ ìœ„í•œ ì¶”ê°€ í•„ë“œ
    private final ConcurrentHashMap<String, Set<String>> visitedUrls = new ConcurrentHashMap<>();
    private static final int WORKER_COUNT = 3; // Consumer ìŠ¤ë ˆë“œ ìˆ˜

    @Override
    public CrawlStatusDto startCrawling(CrawlRequestDto request) {
        if (isCrawling.get()) {
            throw new RuntimeException("í¬ë¡¤ë§ì´ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤");
        }

        log.info("ê¸°ë³¸ í¬ë¡¤ë§ ì‹œì‘ ìš”ì²­: category={}", request.getCategory());

        // í¬ë¡¤ë§ ìƒíƒœ ì„¤ì •
        isCrawling.set(true);
        currentCategory.set(request.getCategory());
        crawlStartTime.set(LocalDateTime.now());
        processedCount.set(0);
        totalCount.set(0);

        // ğŸ”¥ CompletableFutureë¡œ ë¹„ë™ê¸° ì‹¤í–‰
        CompletableFuture.runAsync(() -> {
            try {
                log.info("ë¹„ë™ê¸° ê¸°ë³¸ í¬ë¡¤ë§ ì‘ì—… ì‹œì‘");
                if (request.getCategory() == null || "ì „ì²´".equals(request.getCategory())) {
                    crawlBasic(); // ì „ì²´ ì¹´í…Œê³ ë¦¬
                } else {
                    crawlCategory(request.getCategory()); // íŠ¹ì • ì¹´í…Œê³ ë¦¬
                }
                log.info("ê¸°ë³¸ í¬ë¡¤ë§ ì‘ì—… ì™„ë£Œ - ì´ ì²˜ë¦¬: {}ê°œ", processedCount.get());
            } catch (Exception e) {
                log.error("ê¸°ë³¸ í¬ë¡¤ë§ ì‘ì—… ì¤‘ ì—ëŸ¬ ë°œìƒ", e);
            } finally {
                isCrawling.set(false);
            }
        });

        return CrawlStatusDto.builder()
                .status(CrawlerStatus.RUNNING)
                .currentCategory(request.getCategory())
                .startTime(crawlStartTime.get())
                .message("ê¸°ë³¸ í¬ë¡¤ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤")
                .build();
    }

    @Override
    public CrawlStatusDto startDeepCrawling(CrawlRequestDto request) {
        if (isDeepCrawling.get()) {
            throw new RuntimeException("ë”¥ í¬ë¡¤ë§ì´ ì´ë¯¸ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤");
        }
        if (request.getCategory() == null) {
            throw new RuntimeException("ì¹´í…Œê³ ë¦¬ê°€ null ì…ë‹ˆë‹¤.");
        }

        log.info("BFS Deep Crawling ì‹œì‘ ìš”ì²­: category={}", request.getCategory());

        // Deep Crawling ìƒíƒœ ì„¤ì •
        isDeepCrawling.set(true);
        currentCategory.set(request.getCategory());
        crawlStartTime.set(LocalDateTime.now());
        deepCrawlProcessedCount.set(0);
        deepCrawlSavedCount.set(0);

        // ğŸ”¥ CompletableFutureë¡œ ë¹„ë™ê¸° ì‹¤í–‰
        CompletableFuture.runAsync(() -> {
            try {
                log.info("ë¹„ë™ê¸° BFS Deep Crawling ì‘ì—… ì‹œì‘");
                crawlDeep(request);
                log.info("BFS Deep Crawling ì‘ì—… ì™„ë£Œ - ì²˜ë¦¬: {}ê°œ, ì €ì¥: {}ê°œ",
                        deepCrawlProcessedCount.get(), deepCrawlSavedCount.get());
            } catch (Exception e) {
                log.error("BFS Deep Crawling ì‘ì—… ì¤‘ ì—ëŸ¬ ë°œìƒ", e);
            } finally {
                isDeepCrawling.set(false);
            }
        });

        return CrawlStatusDto.builder()
                .status(CrawlerStatus.RUNNING)
                .currentCategory(request.getCategory())
                .startTime(crawlStartTime.get())
                .message("BFS Deep Crawlingì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤")
                .build();
    }

    @Override
    public CrawlStatusDto stopCrawling() {
        boolean wasCrawling = isCrawling.get() || isDeepCrawling.get();

        if (!wasCrawling) {
            throw new RuntimeException("ì‹¤í–‰ ì¤‘ì¸ í¬ë¡¤ë§ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤");
        }

        log.info("í¬ë¡¤ë§ ì¤‘ì§€ ìš”ì²­");

        // í˜„ì¬ ì‘ì—… ì·¨ì†Œ
        if (currentCrawlTask != null && !currentCrawlTask.isDone()) {
            currentCrawlTask.cancel(true);
        }

        // ìƒíƒœ ì´ˆê¸°í™”
        resetCrawlingState();

        return CrawlStatusDto.builder()
                .status(CrawlerStatus.IDLE)
                .message("í¬ë¡¤ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
                .build();
    }

    @Override
    public CrawlStatusDto getCurrentStatus() {
        if (isCrawling.get()) {
            return CrawlStatusDto.builder()
                    .status(CrawlerStatus.RUNNING)
                    .currentCategory(currentCategory.get())
                    .startTime(crawlStartTime.get())
                    .processedArticles(processedCount.get())
                    .errorCounts(new HashMap<>(errorCounts))
                    .lastExecutionTimes(new HashMap<>(lastExecutionTimes))
                    .message("ê¸°ë³¸ í¬ë¡¤ë§ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤")
                    .build();
        } else if (isDeepCrawling.get()) {
            return CrawlStatusDto.builder()
                    .status(CrawlerStatus.RUNNING)
                    .currentCategory(currentCategory.get())
                    .startTime(crawlStartTime.get())
                    .processedArticles(deepCrawlProcessedCount.get())
                    .errorCounts(new HashMap<>(errorCounts))
                    .lastExecutionTimes(new HashMap<>(lastExecutionTimes))
                    .message("BFS Deep Crawlingì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤")
                    .build();
        } else {
            return CrawlStatusDto.builder()
                    .status(CrawlerStatus.IDLE)
                    .errorCounts(new HashMap<>(errorCounts))
                    .lastExecutionTimes(new HashMap<>(lastExecutionTimes))
                    .message("í¬ë¡¤ë§ ëŒ€ê¸° ì¤‘")
                    .build();
        }
    }

    @Override
    public StatsResponseDto getCrawlingStats() {
        return articleService.getArticleStats();
    }

    @Override
    public Map<String, String> getLastExecutionTimes() {
        Map<String, String> result = new HashMap<>();
        DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss");

        lastExecutionTimes.forEach((category, time) -> {
            result.put(category, time.format(formatter));
        });

        return result;
    }

    @Override
    public Map<String, Double> getSuccessRates() {
        Map<String, Double> successRates = new HashMap<>();

        NaverNewsSchemas.getCategoryUrls().keySet().forEach(category -> {
            double successRate = calculateSuccessRate(category);
            successRates.put(category, successRate);
        });

        return successRates;
    }

    // ===== ê¸°ë³¸ í¬ë¡¤ë§ ë©”ì„œë“œë“¤ =====

    private void crawlBasic() {
        NaverNewsSchemas.getCategoryUrls().keySet().forEach(category -> {
            try {
                log.info("ì¹´í…Œê³ ë¦¬ {} ê¸°ë³¸ í¬ë¡¤ë§ ì‹œì‘", category);
                crawlCategory(category);
                log.info("ì¹´í…Œê³ ë¦¬ {} ê¸°ë³¸ í¬ë¡¤ë§ ì™„ë£Œ", category);
            } catch (Exception e) {
                log.error("ì¹´í…Œê³ ë¦¬ {} ê¸°ë³¸ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ", category, e);
                // í•œ ì¹´í…Œê³ ë¦¬ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ëŠ” ê³„ì† ì§„í–‰
            }
        });
    }

    // ===== BFS Deep Crawling ë©”ì„œë“œë“¤ =====

    /**
     * BFS Deep Crawling ì‹¤í–‰
     */
    private void crawlDeep(CrawlRequestDto request) {
        String category = request.getCategory();

        if ("ì „ì²´".equals(category)) {
            // ì „ì²´ ì¹´í…Œê³ ë¦¬ BFS Deep Crawling
            crawlAllCategoriesDeep();
        } else {
            // ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ BFS Deep Crawling
            String categoryUrl = NaverNewsSchemas.getCategoryUrls().get(category);
            if (categoryUrl != null) {
                crawlSingleCategoryDeep(category, categoryUrl);
            } else {
                log.error("ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬: {}", category);
            }
        }
    }

    /**
     * ì „ì²´ ì¹´í…Œê³ ë¦¬ BFS Deep Crawling
     */
    private void crawlAllCategoriesDeep() {
        log.info("ì „ì²´ ì¹´í…Œê³ ë¦¬ BFS Deep Crawling ì‹œì‘");

        NaverNewsSchemas.getCategoryUrls().forEach((category, url) -> {
            if (!isDeepCrawling.get()) {
                log.info("Deep Crawling ì¤‘ë‹¨ ìš”ì²­ìœ¼ë¡œ ì‘ì—… ì¢…ë£Œ");
                return;
            }

            try {
                currentCategory.set(category);
                log.info("ì¹´í…Œê³ ë¦¬ {} BFS Deep Crawling ì‹œì‘", category);

                crawlSingleCategoryDeep(category, url);

                log.info("ì¹´í…Œê³ ë¦¬ {} BFS Deep Crawling ì™„ë£Œ", category);

                // ì¹´í…Œê³ ë¦¬ ê°„ ë”œë ˆì´
                Thread.sleep(3000);

            } catch (Exception e) {
                log.error("ì¹´í…Œê³ ë¦¬ {} BFS Deep Crawling ì¤‘ ì˜¤ë¥˜", category, e);
                updateFailureMetrics(category);
            }
        });

        log.info("ì „ì²´ ì¹´í…Œê³ ë¦¬ BFS Deep Crawling ì™„ë£Œ");
    }

    /**
     * ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ BFS Deep Crawling
     */
    private void crawlSingleCategoryDeep(String category, String categoryUrl) {
        log.info("ì¹´í…Œê³ ë¦¬ {} BFS Deep Crawling ì‹œì‘: {}", category, categoryUrl);

        long startTime = System.currentTimeMillis();
        AtomicInteger categoryProcessedCount = new AtomicInteger(0);
        AtomicInteger categorySavedCount = new AtomicInteger(0);

        try {
            // BFS Deep Crawling ì‹¤í–‰
            CompletableFuture<List<StreamingCrawlResult>> crawlFuture =
                    crawl4AIClient.crawlNaverNewsBFS(categoryUrl, result -> {
                        // ì§„í–‰ ìƒí™© ì²˜ë¦¬
                        handleStreamingProgress(result, category, categoryProcessedCount, categorySavedCount);
                    });

            // ê²°ê³¼ ëŒ€ê¸°
            List<StreamingCrawlResult> results = crawlFuture.get();

            long crawlTime = System.currentTimeMillis() - startTime;
            int processedPages = categoryProcessedCount.get();
            int savedArticles = categorySavedCount.get();

            // ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            updateDeepCrawlMetrics(category, processedPages, savedArticles, crawlTime);

        } catch (Exception e) {
            log.error("ì¹´í…Œê³ ë¦¬ {} BFS Deep Crawling ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜", category, e);
            updateFailureMetrics(category);
        } finally {
            crawlerMetrics.updateCrawlStatus(category, false);
        }
    }

    /**
     * ìŠ¤íŠ¸ë¦¬ë° ì§„í–‰ ìƒí™© ì²˜ë¦¬
     */
    private void handleStreamingProgress(StreamingCrawlResult result, String category,
                                         AtomicInteger categoryProcessedCount,
                                         AtomicInteger categorySavedCount) {
        if (result.isPageSuccessful()) {
            int processed = categoryProcessedCount.incrementAndGet();

            log.debug("ì¹´í…Œê³ ë¦¬ {} - BFS í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ ({}/{}): {}",
                    category,
                    processed,
                    result.getTotalEstimatedPages(),
                    result.getCurrentUrl());

            // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            crawlerMetrics.updateCrawlStatus(category, true);
            deepCrawlProcessedCount.incrementAndGet();

            // ê¸°ì‚¬ ì €ì¥ ì‹œë„
            try {
                if (saveStreamingResultToDatabase(result, category)) {
                    int saved = categorySavedCount.incrementAndGet();
                    deepCrawlSavedCount.incrementAndGet();
                    log.debug("ì¹´í…Œê³ ë¦¬ {} - BFS ê¸°ì‚¬ ì €ì¥ ì™„ë£Œ ({}ë²ˆì§¸)", category, saved);
                }
            } catch (Exception e) {
                log.warn("BFS ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {}", result.getCurrentUrl(), e);
            }
        }
    }

    /**
     * ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
     */
    @Transactional
    protected boolean saveStreamingResultToDatabase(StreamingCrawlResult streamingResult, String category) {
        try {
            if (!streamingResult.isPageSuccessful() || !streamingResult.hasPageContent()) {
                return false;
            }

            String url = streamingResult.getCurrentUrl();

            // ì¤‘ë³µ ì²´í¬
            if (articleRepository.existsByLink(url)) {
                log.debug("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” BFS ê¸°ì‚¬ ìŠ¤í‚µ: {}", url);
                return false;
            }

            // ë§ˆí¬ë‹¤ìš´ì—ì„œ ì œëª©ê³¼ ë‚´ìš© ì¶”ì¶œ
            String markdown = streamingResult.getPageResult().getMarkdown();
            if (markdown == null || markdown.trim().isEmpty()) {
                log.debug("BFS ë§ˆí¬ë‹¤ìš´ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {}", url);
                return false;
            }

            // ê°„ë‹¨í•œ ì œëª© ì¶”ì¶œ (ì²« ë²ˆì§¸ # í—¤ë” ë˜ëŠ” URLì—ì„œ ì¶”ì¶œ)
            String title = extractTitleFromMarkdown(markdown, url);
            String content = cleanMarkdownContent(markdown);

            if (content.length() < 100) {
                log.debug("BFS ê¸°ì‚¬ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ: {} ({}ì)", url, content.length());
                return false;
            }

            // Article ì €ì¥ (ê¸°ì¡´ saveArticle ë©”ì„œë“œ ì¬ì‚¬ìš©)
            Article article = saveBFSArticle(title, content, url, category, streamingResult);

            log.debug("BFS Deep Crawling ê¸°ì‚¬ ì €ì¥ ì™„ë£Œ: {} - {}", article.getId(), title);
            return true;

        } catch (Exception e) {
            log.error("BFS ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {}", streamingResult.getCurrentUrl(), e);
            return false;
        }
    }

    /**
     * BFS Deep Crawling ê²°ê³¼ë¡œ Article ì €ì¥ (ê¸°ì¡´ ë©”ì„œë“œì™€ ìœ ì‚¬í•˜ì§€ë§Œ ì†ŒìŠ¤ êµ¬ë¶„)
     */
    private Article saveBFSArticle(String title, String content, String url, String category,
                                   StreamingCrawlResult streamingResult) {
        String storedDate = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd"));

        Article.ArticleBuilder builder = Article.builder()
                .title(title)
                .content(content)
                .link(url)
                .category(category)
                .storedDate(storedDate)
                .source("ë„¤ì´ë²„ë‰´ìŠ¤_BFS") // BFS í¬ë¡¤ë§ì„ì„ í‘œì‹œ
                .publishedAt(LocalDateTime.now())
                .articleTextLength(content.length())
                .viewsCount(0)
                .version(1)
                .isDeleted(false);

        // Deep Crawling ë©”íƒ€ë°ì´í„° ì¶”ê°€
        if (streamingResult.getMetadata() != null) {
            // ìŠ¤ì½”ì–´ë¥¼ sentimentë¡œ í™œìš©
            if (streamingResult.getMetadata().getScore() != null) {
                builder.sentimentScore(streamingResult.getMetadata().getScore());
            }
        }

        return articleRepository.save(builder.build());
    }

    /**
     * Deep Crawling ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
     */
    private void updateDeepCrawlMetrics(String category, int processedPages, int savedArticles, long crawlTime) {
        if (processedPages > 0) {
            crawlerMetrics.incrementCrawlSuccess(category);
            crawlerMetrics.recordCrawlTime(category, crawlTime);
            crawlerMetrics.incrementArticlesProcessed(category, savedArticles);

            log.info("ì¹´í…Œê³ ë¦¬ {} BFS Deep Crawling ì™„ë£Œ - ì²˜ë¦¬: {}í˜ì´ì§€, ì €ì¥: {}ê¸°ì‚¬, ì†Œìš”ì‹œê°„: {}ms",
                    category, processedPages, savedArticles, crawlTime);
        } else {
            crawlerMetrics.incrementCrawlFailure(category);
            log.warn("ì¹´í…Œê³ ë¦¬ {} BFS Deep Crawling ì‹¤íŒ¨ - ì²˜ë¦¬ëœ í˜ì´ì§€ ì—†ìŒ", category);
        }

        lastExecutionTimes.put(category, LocalDateTime.now());
    }

    // ===== ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤ =====

    /**
     * ë§ˆí¬ë‹¤ìš´ì—ì„œ ì œëª© ì¶”ì¶œ
     */
    private String extractTitleFromMarkdown(String markdown, String url) {
        // ì²« ë²ˆì§¸ # í—¤ë” ì°¾ê¸°
        String[] lines = markdown.split("\n");
        for (String line : lines) {
            line = line.trim();
            if (line.startsWith("# ") && line.length() > 2) {
                return line.substring(2).trim();
            }
        }

        // í—¤ë”ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ì¤„ ì‚¬ìš©
        for (String line : lines) {
            line = line.trim();
            if (!line.isEmpty() && !line.startsWith("[") && line.length() > 10) {
                return line.length() > 100 ? line.substring(0, 100) + "..." : line;
            }
        }

        // ê·¸ê²ƒë„ ì—†ìœ¼ë©´ URLì—ì„œ ì¶”ì¶œ
        return "ë‰´ìŠ¤ ê¸°ì‚¬ - " + url.substring(url.lastIndexOf("/") + 1);
    }

    /**
     * ë§ˆí¬ë‹¤ìš´ ë‚´ìš© ì •ë¦¬
     */
    private String cleanMarkdownContent(String markdown) {
        // ê¸°ë³¸ì ì¸ ë§ˆí¬ë‹¤ìš´ ì •ë¦¬
        return markdown
                .replaceAll("\\[([^\\]]+)\\]\\([^)]+\\)", "$1") // ë§í¬ ì œê±°
                .replaceAll("#{1,6}\\s*", "")                    // í—¤ë” ë§ˆí¬ ì œê±°
                .replaceAll("\\*\\*([^*]+)\\*\\*", "$1")        // ë³¼ë“œ ì œê±°
                .replaceAll("\\*([^*]+)\\*", "$1")              // ì´íƒ¤ë¦­ ì œê±°
                .replaceAll("\\n{3,}", "\n\n")                  // ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì •ë¦¬
                .trim();
    }

    // ===== ê¸°ì¡´ ë©”ì„œë“œë“¤ (ê·¸ëŒ€ë¡œ ìœ ì§€) =====

    private void crawlCategory(String category) throws JsonProcessingException {
        String url = NaverNewsSchemas.getCategoryUrls().get(category);
        Map<String, Object> schema1 = NaverNewsSchemas.getUrlListSchema();
        Crawl4AIRequest getUrlRequest = Crawl4AIRequest.forUrlList(url, schema1);
        Crawl4AIResult urlResult = crawl4AIClient.crawl(getUrlRequest, true);

        String extractedArray = urlResult.getResult().getExtractedContent();
        JsonNode arrayNode = objectMapper.readTree(extractedArray);
        log.info("ì¹´í…Œê³ ë¦¬ {}: {}ê°œ URL ìˆ˜ì§‘ ì™„ë£Œ", category, arrayNode.size());
        int savedCount = 0;
        int skippedCount = 0;

        for (int i = 0; i < arrayNode.size(); i++) {
            try {
                JsonNode item = arrayNode.get(i);
                String link = getTextValue(item, "link");
                String title = getTextValue(item, "title");

                // ì¤‘ë³µ ì²´í¬ (ì´ë¯¸ êµ¬í˜„ëœ ë©”ì„œë“œ í™œìš©)
                if (articleRepository.existsByLink(link)) {
                    log.debug("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê¸°ì‚¬ ìŠ¤í‚µ: {}", link);
                    skippedCount++;
                    continue;
                }

                // ê°œë³„ ê¸°ì‚¬ ë‚´ìš© í¬ë¡¤ë§
                Article savedArticle = crawlAndSaveArticle(link, title, category);
                if (savedArticle != null) {
                    savedCount++;
                    processedCount.incrementAndGet(); // ì „ì²´ ì¹´ìš´í„° ì¦ê°€
                    log.debug("ê¸°ì‚¬ ì €ì¥ ì™„ë£Œ: {} - {}", savedArticle.getId(), title);
                }

            } catch (Exception e) {
                log.warn("ê°œë³„ ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ (ì¸ë±ìŠ¤: {})", i, e);
                // ê°œë³„ ê¸°ì‚¬ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            }
        }
        log.info("ì¹´í…Œê³ ë¦¬ {} ì²˜ë¦¬ ì™„ë£Œ - ì €ì¥: {}ê°œ, ìŠ¤í‚µ: {}ê°œ", category, savedCount, skippedCount);
    }

    private String getTextValue(JsonNode node, String fieldName) {
        if (node.has(fieldName) && !node.get(fieldName).isNull()) {
            String value = node.get(fieldName).asText();
            return value.isEmpty() ? null : value;
        }
        return null;
    }

    @Transactional
    protected Article crawlAndSaveArticle(String link, String title, String category) throws Exception {
        Map<String, Object> schema2 = NaverNewsSchemas.getContentSchema();
        Crawl4AIRequest request2 = Crawl4AIRequest.forArticleContent(link, schema2);
        Crawl4AIResult result2 = crawl4AIClient.crawl(request2, false);

        String extractedArticle = result2.getResult().getExtractedContent();
        JsonNode articleNode = objectMapper.readTree(extractedArticle);

        if (articleNode.size() == 0) {
            log.warn("ê¸°ì‚¬ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}", link);
            return null;
        }

        JsonNode articleItem = articleNode.get(0);
        String content = getTextValue(articleItem, "content");  // schemaì— ë§ê²Œ ìˆ˜ì •
        String images = getTextValue(articleItem, "image");
        String imageAlts = getTextValue(articleItem, "image_alts");

        // ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
        if (content == null || content.trim().isEmpty()) {
            log.warn("ê¸°ì‚¬ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {}", link);
            return null;
        }

        // Article ì €ì¥
        Article article = saveArticle(title, content, link, category);

        // ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ Mediaë¡œ ì €ì¥
        if (images != null && !images.trim().isEmpty()) {
            saveMediaForArticle(article, images, imageAlts);
        }

        return article;
    }

    // saveArticle ë©”ì„œë“œ ìˆ˜ì •
    private Article saveArticle(String title, String content, String link, String category) {
        String storedDate = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd"));

        Article article = Article.builder()
                .title(title)
                .content(content)
                .link(link)
                .category(category)
                .storedDate(storedDate)
                .source("ë„¤ì´ë²„ë‰´ìŠ¤")
                .publishedAt(LocalDateTime.now())
                .articleTextLength(content.length())
                .viewsCount(0)
                .version(1)
                .isDeleted(false)
                .build();

        return articleRepository.save(article);
    }

    private void saveMediaForArticle(Article article, String imagesStr, String imageAlts) {
        String storedDate = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd"));

        // ì´ë¯¸ì§€ URLê³¼ alt í…ìŠ¤íŠ¸ë¥¼ ë°°ì—´ë¡œ ë¶„ë¦¬
        String[] imageUrls = imagesStr.split(",");
        String[] altTexts = imageAlts != null ? imageAlts.split(",") : new String[0];

        for (int i = 0; i < imageUrls.length; i++) {
            String trimmedUrl = imageUrls[i].trim();
            if (!trimmedUrl.isEmpty()) {
                // í•´ë‹¹ ì¸ë±ìŠ¤ì— alt í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ null
                String caption = i < altTexts.length ? altTexts[i].trim() : null;

                Media media = Media.builder()
                        .article(article)
                        .storedDate(storedDate)
                        .type("image")  // ê¸°ì¡´ ì—”í‹°í‹°ì˜ type í•„ë“œ ì‚¬ìš©
                        .url(trimmedUrl)
                        .caption(caption)  // ê¸°ì¡´ ì—”í‹°í‹°ì˜ caption í•„ë“œ ì‚¬ìš©
                        .build();

                mediaRepository.save(media);
            }
        }
    }


    /**
     * ì„±ê³µ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
     */
    private void updateSuccessMetrics(String category, int articleCount, long crawlTime) {
        crawlerMetrics.incrementCrawlSuccess(category);
        crawlerMetrics.recordCrawlTime(category, crawlTime);
        errorCounts.put(category, 0);
    }

    /**
     * ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
     */
    private void updateFailureMetrics(String category) {
        crawlerMetrics.incrementCrawlFailure(category);
        errorCounts.merge(category, 1, Integer::sum);
    }

    /**
     * í¬ë¡¤ë§ ì˜¤ë¥˜ ì²˜ë¦¬
     */
    private void handleCrawlingError(String category, Exception e) {
        updateFailureMetrics(category);
        log.error("í¬ë¡¤ë§ ì˜¤ë¥˜ ì²˜ë¦¬: category={}", category, e);
    }

    /**
     * í¬ë¡¤ë§ ìƒíƒœ ì´ˆê¸°í™”
     */
    private void resetCrawlingState() {
        isCrawling.set(false);
        isDeepCrawling.set(false);
        currentCategory.set(null);
        crawlStartTime.set(null);
        currentCrawlTask = null;
        visitedUrls.clear(); // ë©”ëª¨ë¦¬ ì •ë¦¬
    }

    /**
     * ì„±ê³µë¥  ê³„ì‚°
     */
    private double calculateSuccessRate(String category) {
        int errorCount = errorCounts.getOrDefault(category, 0);
        return errorCount == 0 ? 95.0 : Math.max(50.0, 95.0 - (errorCount * 10));
    }
}
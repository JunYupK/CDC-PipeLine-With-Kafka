package org.be.crawlerservice.dto.crawl4ai;

import com.fasterxml.jackson.annotation.JsonProperty;
import lombok.AllArgsConstructor;
import lombok.Builder;
import lombok.Data;
import lombok.NoArgsConstructor;

import java.util.List;
import java.util.Map;

@Data
@Builder
@NoArgsConstructor
@AllArgsConstructor
public class Crawl4AIRequest {

    /**
     * í¬ë¡¤ë§í•  URL ë°°ì—´ (Crawl4AIëŠ” ë°°ì—´ì„ ê¸°ëŒ€í•¨)
     */
    private List<String> urls;

    /**
     * ë¸Œë¼ìš°ì € ì„¤ì • (Crawl4AI Docker API í˜•ì‹)
     */
    @JsonProperty("browser_config")
    private ConfigWrapper browserConfig;

    /**
     * í¬ë¡¤ëŸ¬ ì„¤ì • (Crawl4AI Docker API í˜•ì‹)
     */
    @JsonProperty("crawler_config")
    private ConfigWrapper crawlerConfig;

    /**
     * ìš°ì„ ìˆœìœ„ (1-10, ë†’ì„ìˆ˜ë¡ ìš°ì„ )
     */
    @Builder.Default
    private Integer priority = 5;

    /**
     * Crawl4AI Docker APIê°€ ê¸°ëŒ€í•˜ëŠ” ì„¤ì • ë˜í¼ í´ë˜ìŠ¤
     */
    @Data
    @Builder
    @NoArgsConstructor
    @AllArgsConstructor
    public static class ConfigWrapper {
        /**
         * ì„¤ì • íƒ€ì… ("BrowserConfig" ë˜ëŠ” "CrawlerRunConfig")
         */
        private String type;

        /**
         * ì‹¤ì œ íŒŒë¼ë¯¸í„°ë“¤
         */
        private Map<String, Object> params;
    }

    // === íŒ©í† ë¦¬ ë©”ì„œë“œë“¤ ===

    /**
     * URL ëª©ë¡ í¬ë¡¤ë§ìš© ìš”ì²­ ìƒì„± (CSS ì¶”ì¶œ í¬í•¨)
     */
    public static Crawl4AIRequest forUrlList(String url, Map<String, Object> schema) {
//        // ë¸Œë¼ìš°ì € ì„¤ì •
        ConfigWrapper browserConfig = ConfigWrapper.builder()
                .type("BrowserConfig")
                .params(Map.of(
                        "headless", true
                ))
                .build();
//
//        // í¬ë¡¤ëŸ¬ ì„¤ì • (ì¶”ì¶œ ì „ëµ í¬í•¨)
        ConfigWrapper crawlerConfig = ConfigWrapper.builder()
                .type("CrawlerRunConfig")
                .params(Map.of(
                        "cache_mode", "bypass",
                        "page_timeout", 60000,
                        "delay_before_return_html", 2.0,
                        "extraction_strategy", Map.of(
                                "type", "JsonCssExtractionStrategy",
                                "params", schema
                        )
                ))
                .build();

        return Crawl4AIRequest.builder()
                .urls(List.of(url))
                .browserConfig(browserConfig)
                .crawlerConfig(crawlerConfig)
                .priority(10)
                .build();
    }

    /**
     * ê¸°ì‚¬ ë‚´ìš© í¬ë¡¤ë§ìš© ìš”ì²­ ìƒì„±
     */
    public static Crawl4AIRequest forArticleContent(String url, Map<String, Object> schema) {
        // ë¸Œë¼ìš°ì € ì„¤ì •
        ConfigWrapper browserConfig = ConfigWrapper.builder()
                .type("BrowserConfig")
                .params(Map.of(
                        "headless", true,
                        "viewport_width", 1920,
                        "viewport_height", 1080
                ))
                .build();

        // í¬ë¡¤ëŸ¬ ì„¤ì •
        ConfigWrapper crawlerConfig = ConfigWrapper.builder()
                .type("CrawlerRunConfig")
                .params(Map.of(
                        "cache_mode", "bypass",
                        "wait_until", "domcontentloaded",
                        "page_timeout", 60000,
                        "delay_before_return_html", 2.0,
                        "extraction_strategy", Map.of(
                                "type", "JsonCssExtractionStrategy",
                                "params", Map.of("schema", schema)
                        )
                ))
                .build();

        return Crawl4AIRequest.builder()
                .urls(List.of(url))
                .browserConfig(browserConfig)
                .crawlerConfig(crawlerConfig)
                .priority(8)
                .build();
    }

    /**
     * ë„¤ì´ë²„ ë‰´ìŠ¤ ì „ìš© BFS Deep Crawling
     */
    public static Crawl4AIRequest forNaverNewsBFS(String categoryUrl) {
        // ë„¤ì´ë²„ ë‰´ìŠ¤ì— íŠ¹í™”ëœ ì„¤ì •
        ConfigWrapper browserConfig = ConfigWrapper.builder()
                .type("BrowserConfig")
                .params(Map.of(
                        "headless", true,
                        "viewport_width", 1920,
                        "viewport_height", 1080,
                        "headers", Map.of(
                                "Accept-Language", "ko-KR,ko;q=0.9,en;q=0.8"
                        )
                ))
                .build();

        ConfigWrapper crawlerConfig = ConfigWrapper.builder()
                .type("CrawlerRunConfig")
                .params(Map.of(
                        "cache_mode", "bypass",
                        "wait_until", "domcontentloaded",
                        "page_timeout", 45000,
                        "stream", true,
                        "deep_crawl_strategy", Map.of(
                                "type", "BFSDeepCrawlStrategy",
                                "params", Map.of(
                                        "max_depth", 2,        // ëª©ë¡ í˜ì´ì§€ -> ê¸°ì‚¬ í˜ì´ì§€
                                        "max_pages", 30,       // ì ë‹¹í•œ ê°œìˆ˜ë¡œ ì œí•œ
                                        "include_external", false,
                                        "score_threshold", 0.2
                                )
                        ),
                        // ë„¤ì´ë²„ ë‰´ìŠ¤ êµ¬ì¡°ì— ë§ëŠ” ì¶”ì¶œ ì„¤ì •
                        "css_selector", "body",
                        "excluded_tags", List.of("script", "style", "nav", "header", "footer"),
                        "word_count_threshold", 50
                ))
                .build();

        return Crawl4AIRequest.builder()
                .urls(List.of(categoryUrl))
                .browserConfig(browserConfig)
                .crawlerConfig(crawlerConfig)
                .priority(9)
                .build();
    }
    /**
     * BFS Deep Crawling ìš”ì²­ ìƒì„± (ë‰´ìŠ¤ ì‚¬ì´íŠ¸ ìµœì í™”)
     */
    public static Crawl4AIRequest forBFSDeepCrawl(String startUrl, int maxDepth, int maxPages, Map<String, Object> schema) {
//        Map<String, Object> schema = Map.of(
//                "name", "NewsArticle",
//                "baseSelector", "body",
//                "fields", List.of(
//                        Map.of(
//                                "name", "title",
//                                "selector", "#title_area > span",
//                                "type", "text"
//                        ),
//                        Map.of(
//                                "name", "content",
//                                "selector", "#dic_area, .news_content, #newsct_article",
//                                "type", "text"
//                        ),
//                        Map.of(
//                                "name", "author",
//                                "selector", ".byline, .author, .media_end_head_journalist",
//                                "type", "text"
//                        ),
//                        Map.of(
//                                "name", "published_date",
//                                "selector", ".date, .published, .media_end_head_info_datestamp",
//                                "type", "text"
//                        )
//                )
//        );
        // ë¸Œë¼ìš°ì € ì„¤ì •
        ConfigWrapper browserConfig = ConfigWrapper.builder()
                .type("BrowserConfig")
                .params(Map.of(
                        "headless", true,
                        "viewport_width", 1920,
                        "viewport_height", 1080,
                        "text_mode", false
                ))
                .build();

        // BFS Deep Crawling ì „ëµì´ í¬í•¨ëœ í¬ë¡¤ëŸ¬ ì„¤ì •
        ConfigWrapper crawlerConfig = ConfigWrapper.builder()
                .type("CrawlerRunConfig")
                .params(Map.of(
                        "cache_mode", "bypass",
                        "stream", true, // ğŸ”¥ ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ
                        "wait_until", "networkidle",
                        "page_timeout", 30000,
                        "delay_before_return_html", 2.0,
                        "extraction_strategy", Map.of(
                                "type", "JsonCssExtractionStrategy",
                                "params", Map.of("schema", schema)
                        ),
                        "deep_crawl_strategy", Map.of(
                                "type", "BFSDeepCrawlStrategy",
                                "params", Map.of(
                                        "max_depth", maxDepth,
                                        "include_external", true,
                                        "max_pages", maxPages,
                                        "score_threshold", 0.0,
                                        "filter_chain", Map.of(
                                                "type", "FilterChain",
                                                "params", Map.of(
                                                        "filters", List.of(
                                                                Map.of(
                                                                        "type", "URLPatternFilter",
                                                                        "params", Map.of(
                                                                                "patterns", List.of("*article*")
                                                                        )
                                                                )
                                                        )
                                                )
                                        )
                                )
                        )
                ))
                .build();

        return Crawl4AIRequest.builder()
                .urls(List.of(startUrl))
                .browserConfig(browserConfig)
                .crawlerConfig(crawlerConfig)
                .priority(8)
                .build();
    }

}
# application.yml - ?? ??
server:
  port: 8080

spring:
  flyway:
    baseline-on-migrate: true
    baseline-version: 0
  application:
    name: crawler-service

  datasource:
    url: jdbc:postgresql://${POSTGRES_IP}:5432/${POSTGRES_DB}
    username: ${POSTGRES_USER}
    password: ${POSTGRES_PASSWORD}
    driver-class-name: org.postgresql.Driver
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000

  jpa:
    hibernate:
      ddl-auto: none
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
    open-in-view: false

  data:
    redis:
      host: localhost
      port: 6379
      password: homesweethome
      timeout: 2000ms
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    streams:
      application-id: alert-streams-app
      default-key-serde: org.apache.kafka.common.serialization.Serdes$StringSerde
      default-value-serde: org.springframework.kafka.support.serializer.JsonSerde
      properties:
        commit.interval.ms: 1000
        cache.max.bytes.buffering: 10240
        default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        default.value.serde: org.springframework.kafka.support.serializer.JsonSerde
        metadata.max.age.ms: 300000
        auto.offset.reset: earliest
        enable.auto.commit: true
        processing.guarantee: at_least_once
  jackson:
    serialization:
      write-dates-as-timestamps: false
    time-zone: Asia/Seoul

# ?? ????? ??
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
    metrics:
      enabled: true
    prometheus:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true

# ??? ??
crawler:
  crawl4ai-url: http://localhost:11235
  api-token: home
  interval-hours: 3
  batch-size: 10
  max-concurrent-tasks: 5
  timeout-seconds: 180

# 알림 서비스 설정
alert:
  topics:
    input: keyword.alert
    breaking-alerts: breaking-alerts
    trending-alerts: trending-alerts

  # 알림 조건 설정
  conditions:
    breaking:
      keyword-threshold: 50  # 키워드 빈도 임계값
      time-window-minutes: 5
      min-sources: 3  # 최소 언론사 수

    trending:
      growth-rate-threshold: 2.0  # 증가율 임계값
      time-window-minutes: 30
      min-mentions: 10

# ?? ??
logging:
  level:
    org.be.crawlerservice: DEBUG
    org.springframework.web: INFO
    org.hibernate.SQL: DEBUG
    org.hibernate.type.descriptor.sql.BasicBinder: TRACE
  pattern:
    console: "%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"

  # 액추에이터 설정
  management:
    endpoints:
      web:
        exposure:
          include: health,info,metrics,kafka-streams
    endpoint:
      health:
        show-details: always
      kafka-streams:
        enabled: true
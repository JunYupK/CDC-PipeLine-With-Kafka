import asyncio
import json
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from collections import defaultdict
import redis.asyncio as redis
import logging

logger = logging.getLogger(__name__)

@dataclass
class TrendMetrics:
    keyword: str
    count_1h: int
    count_6h: int
    count_24h: int
    count_7d: int
    velocity_1h: float
    velocity_6h: float
    z_score: float
    anomaly_score: float
    trend_direction: str  # "rising", "falling", "stable"
    compound_score: float

@dataclass
class AlertTrigger:
    keyword: str
    alert_type: str  # "breakout", "anomaly", "trending"
    score: float
    timestamp: datetime
    metadata: Dict

class AdvancedTrendAnalyzer:
    def __init__(self):
        self.redis_client = None
        self.alert_callbacks = []
        
        # ì‹œê°„ ìœˆë„ìš° ì„¤ì • (ì‹œê°„ ë‹¨ìœ„)
        self.time_windows = [1, 6, 24, 168]  # 1h, 6h, 24h, 7d
        
        # ì•Œë¦¼ ì„ê³„ê°’
        self.alert_thresholds = {
            "breakout_ratio": 3.0,
            "velocity_min": 10,
            "z_score_min": 2.0,
            "anomaly_min": 0.8
        }
        
    async def initialize(self, redis_url: str = "redis://localhost:6379"):
        """Redis ì—°ê²° ì´ˆê¸°í™”"""
        self.redis_client = redis.from_url(redis_url, decode_responses=True)
        await self.redis_client.ping()
        logger.info("âœ… ê³ ë„í™”ëœ íŠ¸ë Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def add_keywords(self, keywords: List[str], category: str = "", article_metadata: Dict = None):
        """í‚¤ì›Œë“œ ì¶”ê°€ ë° ë‹¤ì°¨ì› íŠ¸ë Œë“œ ì—…ë°ì´íŠ¸"""
        current_time = datetime.now()
        
        for keyword in keywords:
            # ê¸°ë³¸ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            await self._update_multi_window_counts(keyword, current_time, category)
            
            # ì´ìƒì¹˜ ê°ì§€ ë° ì•Œë¦¼ ì²´í¬
            await self._check_trend_alerts(keyword, category)
    
    async def _update_multi_window_counts(self, keyword: str, timestamp: datetime, category: str):
        """ë‹¤ì¤‘ ì‹œê°„ ìœˆë„ìš° ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸"""
        pipeline = self.redis_client.pipeline()
        
        # ì „ì²´ ì¹´ìš´íŠ¸
        pipeline.zincrby("trending_keywords", 1, keyword)
        
        # ì‹œê°„ ìœˆë„ìš°ë³„ ì¹´ìš´íŠ¸
        for window_hours in self.time_windows:
            window_key = f"keywords:{window_hours}h:{timestamp.strftime('%Y%m%d%H')}"
            pipeline.zincrby(window_key, 1, keyword)
            pipeline.expire(window_key, window_hours * 3600 + 86400)  # ìœˆë„ìš° + 1ì¼ ì—¬ìœ 
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì¹´ìš´íŠ¸
        if category:
            cat_key = f"keywords:category:{category}"
            pipeline.zincrby(cat_key, 1, keyword)
        
        # ì‹œê°„ë³„ ì„¸ë¶€ ì¹´ìš´íŠ¸ (ì°¨íŠ¸ìš©)
        minute_key = f"keywords:timeline:{timestamp.strftime('%Y%m%d%H%M')}"
        pipeline.zincrby(minute_key, 1, keyword)
        pipeline.expire(minute_key, 604800)  # 7ì¼ ë³´ê´€
        
        await pipeline.execute()
    
    async def calculate_trend_metrics(self, keyword: str) -> TrendMetrics:
        """ì¢…í•© íŠ¸ë Œë“œ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        current_time = datetime.now()
        
        # ë‹¤ì¤‘ ìœˆë„ìš° ì¹´ìš´íŠ¸ ìˆ˜ì§‘
        counts = await self._get_multi_window_counts(keyword, current_time)
        
        # ì†ë„ ê³„ì‚° (ì‹œê°„ë‹¹ ì¦ê°€ìœ¨)
        velocity_1h = await self._calculate_velocity(keyword, 1, current_time)
        velocity_6h = await self._calculate_velocity(keyword, 6, current_time)
        
        # í†µê³„ì  ì´ìƒì¹˜ ê°ì§€
        z_score, anomaly_score = await self._detect_anomaly(keyword)
        
        # íŠ¸ë Œë“œ ë°©í–¥ íŒì •
        trend_direction = self._determine_trend_direction(velocity_1h, velocity_6h)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        compound_score = self._calculate_compound_score(counts, velocity_1h, z_score, anomaly_score)
        
        return TrendMetrics(
            keyword=keyword,
            count_1h=counts.get("1h", 0),
            count_6h=counts.get("6h", 0),
            count_24h=counts.get("24h", 0),
            count_7d=counts.get("168h", 0),
            velocity_1h=velocity_1h,
            velocity_6h=velocity_6h,
            z_score=z_score,
            anomaly_score=anomaly_score,
            trend_direction=trend_direction,
            compound_score=compound_score
        )
    
    async def _get_multi_window_counts(self, keyword: str, current_time: datetime) -> Dict[str, int]:
        """ë‹¤ì¤‘ ì‹œê°„ ìœˆë„ìš° ì¹´ìš´íŠ¸ ì¡°íšŒ"""
        counts = {}
        
        for window_hours in self.time_windows:
            total_count = 0
            
            # í˜„ì¬ ì‹œê°„ë¶€í„° ìœˆë„ìš°ë§Œí¼ ì—­ì‚°
            for i in range(min(window_hours, 24)):  # ìµœëŒ€ 24ì‹œê°„ìœ¼ë¡œ ì œí•œ
                hour_time = current_time - timedelta(hours=i)
                window_key = f"keywords:{window_hours}h:{hour_time.strftime('%Y%m%d%H')}"
                try:
                    count = await self.redis_client.zscore(window_key, keyword) or 0
                    total_count += int(count)
                except:
                    continue
            
            counts[f"{window_hours}h"] = total_count
        
        return counts
    
    async def _calculate_velocity(self, keyword: str, window_hours: int, current_time: datetime) -> float:
        """ì†ë„ ê³„ì‚° (í˜„ì¬ vs ì´ì „ ê¸°ê°„)"""
        # í˜„ì¬ ê¸°ê°„
        current_count = 0
        for i in range(window_hours):
            hour_time = current_time - timedelta(hours=i)
            window_key = f"keywords:{window_hours}h:{hour_time.strftime('%Y%m%d%H')}"
            count = await self.redis_client.zscore(window_key, keyword) or 0
            current_count += int(count)
        
        # ì´ì „ ê¸°ê°„
        previous_count = 0
        for i in range(window_hours):
            hour_time = current_time - timedelta(hours=window_hours + i)
            window_key = f"keywords:{window_hours}h:{hour_time.strftime('%Y%m%d%H')}"
            count = await self.redis_client.zscore(window_key, keyword) or 0
            previous_count += int(count)
        
        if previous_count == 0:
            return current_count * 2.0  # ìƒˆ í‚¤ì›Œë“œ
        
        return (current_count - previous_count) / window_hours
    
    async def _detect_anomaly(self, keyword: str) -> Tuple[float, float]:
        """í†µê³„ì  ì´ìƒì¹˜ ê°ì§€"""
        # ê³¼ê±° 7ì¼ ì‹œê°„ë³„ ë°ì´í„° ìˆ˜ì§‘
        historical_counts = []
        current_time = datetime.now()
        
        for i in range(168):  # 7ì¼ * 24ì‹œê°„
            hour_time = current_time - timedelta(hours=i)
            window_key = f"keywords:1h:{hour_time.strftime('%Y%m%d%H')}"
            count = await self.redis_client.zscore(window_key, keyword) or 0
            historical_counts.append(int(count))
        
        if len(historical_counts) < 24:  # ìµœì†Œ 24ì‹œê°„ ë°ì´í„° í•„ìš”
            return 0.0, 0.0
        
        # í†µê³„ ê³„ì‚°
        mean = np.mean(historical_counts[1:])  # í˜„ì¬ ì‹œê°„ ì œì™¸
        std = np.std(historical_counts[1:])
        current_count = historical_counts[0]
        
        # Z-score ê³„ì‚°
        z_score = (current_count - mean) / std if std > 0 else 0
        
        # ì´ìƒì¹˜ ì ìˆ˜ (0-1)
        anomaly_score = min(abs(z_score) / 3.0, 1.0)  # 3-sigma ê¸°ì¤€ ì •ê·œí™”
        
        return float(z_score), float(anomaly_score)
    
    def _determine_trend_direction(self, velocity_1h: float, velocity_6h: float) -> str:
        """íŠ¸ë Œë“œ ë°©í–¥ íŒì •"""
        if velocity_1h > 2.0 and velocity_6h > 1.0:
            return "rising"
        elif velocity_1h < -1.0 and velocity_6h < -0.5:
            return "falling"
        else:
            return "stable"
    
    def _calculate_compound_score(self, counts: Dict, velocity_1h: float, z_score: float, anomaly_score: float) -> float:
        """ì¢…í•© íŠ¸ë Œë“œ ì ìˆ˜ ê³„ì‚°"""
        weights = {
            "frequency": 0.25,    # ì ˆëŒ€ ë¹ˆë„
            "velocity": 0.30,     # ì¦ê°€ ì†ë„
            "anomaly": 0.25,      # ì´ìƒì¹˜ ì •ë„
            "momentum": 0.20      # ì§€ì†ì„±
        }
        
        # ì •ê·œí™”ëœ ì ìˆ˜ë“¤
        frequency_score = min(counts.get("1h", 0) / 10.0, 10.0)  # 0-10
        velocity_score = min(max(velocity_1h, 0) / 5.0, 10.0)    # 0-10
        anomaly_score_norm = anomaly_score * 10.0                # 0-10
        momentum_score = min(counts.get("6h", 0) / counts.get("24h", 1), 5.0) * 2  # 0-10
        
        compound = (
            frequency_score * weights["frequency"] +
            velocity_score * weights["velocity"] +
            anomaly_score_norm * weights["anomaly"] +
            momentum_score * weights["momentum"]
        ) * 10  # 0-100 ìŠ¤ì¼€ì¼
        
        return round(compound, 2)
    
    async def _check_trend_alerts(self, keyword: str, category: str):
        """ì‹¤ì‹œê°„ ì•Œë¦¼ ì²´í¬"""
        metrics = await self.calculate_trend_metrics(keyword)
        
        alerts = []
        
        # ê¸‰ìƒìŠ¹ ì•Œë¦¼
        if (metrics.velocity_1h > self.alert_thresholds["velocity_min"] and 
            metrics.z_score > self.alert_thresholds["z_score_min"]):
            alerts.append(AlertTrigger(
                keyword=keyword,
                alert_type="breakout",
                score=metrics.compound_score,
                timestamp=datetime.now(),
                metadata={"category": category, "velocity": metrics.velocity_1h}
            ))
        
        # ì´ìƒì¹˜ ì•Œë¦¼
        if metrics.anomaly_score > self.alert_thresholds["anomaly_min"]:
            alerts.append(AlertTrigger(
                keyword=keyword,
                alert_type="anomaly",
                score=metrics.anomaly_score,
                timestamp=datetime.now(),
                metadata={"z_score": metrics.z_score}
            ))
        
        # ì•Œë¦¼ ë°œì†¡
        for alert in alerts:
            await self._trigger_alert(alert)
    
    async def _trigger_alert(self, alert: AlertTrigger):
        """ì•Œë¦¼ ë°œì†¡"""
        # Redisì— ì•Œë¦¼ ì €ì¥
        alert_data = {
            "keyword": alert.keyword,
            "type": alert.alert_type,
            "score": alert.score,
            "timestamp": alert.timestamp.isoformat(),
            "metadata": json.dumps(alert.metadata)
        }
        
        await self.redis_client.lpush("trending_alerts", json.dumps(alert_data))
        await self.redis_client.ltrim("trending_alerts", 0, 99)  # ìµœê·¼ 100ê°œë§Œ ë³´ê´€
        
        # WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸ìš© ì´ë²¤íŠ¸ ë°œí–‰
        await self.redis_client.publish("alert_channel", json.dumps(alert_data))
        
        logger.info(f"ğŸš¨ íŠ¸ë Œë“œ ì•Œë¦¼: {alert.keyword} - {alert.alert_type} (ì ìˆ˜: {alert.score})")
    
    async def get_trending_keywords_advanced(self, limit: int = 20) -> List[TrendMetrics]:
        """ê³ ë„í™”ëœ íŠ¸ë Œë”© í‚¤ì›Œë“œ ì¡°íšŒ"""
        try:
            # Redis ì—°ê²° í™•ì¸
            await self.redis_client.ping()
        except:
            # ì¬ì—°ê²° ì‹œë„
            await self.initialize(redis_url="redis://:homesweethome@localhost:6379")
        
        # ìƒìœ„ í‚¤ì›Œë“œ í›„ë³´ ì¡°íšŒ (ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§)
        candidates = await self.redis_client.zrevrange("trending_keywords", 0, limit * 2, withscores=True)
        
        trending_metrics = []
        for keyword, _ in candidates:
            try:
                metrics = await self.calculate_trend_metrics(keyword)
                trending_metrics.append(metrics)
            except Exception as e:
                logger.error(f"í‚¤ì›Œë“œ {keyword} ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}")
                continue
        
        # ì¢…í•© ì ìˆ˜ë¡œ ì •ë ¬
        trending_metrics.sort(key=lambda x: x.compound_score, reverse=True)
        
        return trending_metrics[:limit]
    
    async def get_timeline_data(self, keyword: str, hours: int = 24) -> List[Dict]:
        """í‚¤ì›Œë“œ ì‹œê°„ë³„ ë°ì´í„° (ì°¨íŠ¸ìš©)"""
        timeline = []
        current_time = datetime.now()
        
        for i in range(hours * 60):  # ë¶„ ë‹¨ìœ„
            time_point = current_time - timedelta(minutes=i)
            minute_key = f"keywords:timeline:{time_point.strftime('%Y%m%d%H%M')}"
            count = await self.redis_client.zscore(minute_key, keyword) or 0
            
            timeline.append({
                "timestamp": time_point.isoformat(),
                "count": int(count)
            })
        
        return list(reversed(timeline))  # ì‹œê°„ìˆœ ì •ë ¬
    
    async def get_recent_alerts(self, limit: int = 10) -> List[Dict]:
        """ìµœê·¼ ì•Œë¦¼ ì¡°íšŒ"""
        alerts_raw = await self.redis_client.lrange("trending_alerts", 0, limit - 1)
        return [json.loads(alert) for alert in alerts_raw]